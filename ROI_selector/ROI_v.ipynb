{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ukaK6_FunAhs",
    "outputId": "253387f8-7cc4-446d-adc3-12abd2b9d196"
   },
   "outputs": [],
   "source": [
    "!conda activate base\n",
    "# Required Importscmd\n",
    "import cv2 as cv2\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.figure as figure\n",
    "import matplotlib.patches as patches\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os \n",
    "\n",
    "#pip install jupyter_innotater\n",
    "from jupyter_innotater import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "5yVDjWwhnKM4",
    "outputId": "7388a871-d82f-44ef-8a2e-ca30d1efd0aa"
   },
   "outputs": [],
   "source": [
    "# Image general definitions\n",
    "filename = \"RUBEM_BERTA_2_60_6_mars-small128\" ## name of the csv file\n",
    "videoname = \"RUBEM_BERTA_2\" ## name of the video\n",
    "\n",
    "\n",
    "data = pd.read_csv(f\"./data/{filename}.csv\", sep=\";\", \n",
    "                   names=[\n",
    "                   \"track_id\",\n",
    "                    \"bbox\",\n",
    "                    \"class\",\n",
    "                    \"frame\"],\n",
    "                    converters={\"bbox\": literal_eval}) ## read the csv file and literal eval as list the bbox field\n",
    "vidcap = cv2.VideoCapture(f\"./data/{videoname}.mp4\") ## open the video file\n",
    "\n",
    "WIDTH = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH)) ## get the with of the frame\n",
    "HEIGHT = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT)) ## get the height of the frame \n",
    "my_dpi = 96 ## pixel density of the current monitor - to ensure the size of image complies with the pixel size of the screen\n",
    "MIN_DISTANCE = 100 ## minimum distance threshold to filter the data\n",
    "\n",
    "fps = vidcap.get(cv2.CAP_PROP_FPS) ## get the fps of the video\n",
    "# Get the total numer of frames in the video.\n",
    "frame_count = vidcap.get(cv2.CAP_PROP_FRAME_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qIoGAsMgny41"
   },
   "outputs": [],
   "source": [
    "## capture the image at 1s in the video - ensure that the image is clear and stable.\n",
    "vidcap.set(cv2.CAP_PROP_POS_MSEC, 1000)  # change the vidcap position\n",
    "_ , image = vidcap.read() ## buffer a call\n",
    "_ , image = vidcap.read() ## then capture the image\n",
    "cv2.imwrite(\"first_frame.png\", image) ## save the image (first frame for defining the entrances and outputs)\n",
    "\n",
    "## Get the center of the bounding boxes based on the bbox data\n",
    "## (0,0 on top left corner)\n",
    "## (WIDTH,HEIGTH on bottom right corner)\n",
    "## xc = x1 + x2 / 2\n",
    "## yc = HEIGTH - (y1 + y2)/2\n",
    "\n",
    "data[\"x\"] = (data.bbox.str[0] +\n",
    "             data.bbox.str[2]) / 2\n",
    "\n",
    "data[\"y\"] = -(data.bbox.str[1] +\n",
    "              data.bbox.str[3]) / 2 + HEIGHT\n",
    "\n",
    "## filter data by track_id\n",
    "grouped = data.groupby(\"track_id\") # group the data by the object ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_id = 2 \n",
    "# model = \"vric\"\n",
    "_time = 0 # Initial time in frames\n",
    "_delta = 300 # frame delta - duration of the logging in the image\n",
    "\n",
    "plt.figure(figsize=(WIDTH/my_dpi, HEIGHT/my_dpi), dpi=my_dpi) # start a figure plot\n",
    "segment = data[(data.frame < _time + _delta) & (data.frame > _time)] # segment of data that we are interested in\n",
    "#segment = data\n",
    "plt.scatter(segment.x, segment.y, c=segment.track_id, cmap='jet', s=12) # plot the scatter with the colormap being the frame index\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"Y\")\n",
    "#plt.colorbar(label=\"Frame Index\")\n",
    "\n",
    "plt.tight_layout() # tight layout\n",
    "plt.savefig(f\"./scatter_{filename}_{_time}_{_delta}.png\", dpi=96) # save the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uB-zo4L-n3KW"
   },
   "outputs": [],
   "source": [
    "def plot_arrow(data, color):\n",
    "    plt.scatter(data[\"x\"].values, data[\"y\"].values,\n",
    "                c='blue', marker='o', s=10, zorder=3) ## size and z position, color blue, plot the raw centers for the entries\n",
    "    plt.scatter(data[\"last_x\"].values,\n",
    "                data[\"last_y\"].values, c='red', marker='o', s=10, zorder=2) ## plot output points, with color red\n",
    "\n",
    "    plt.quiver(data[\"x\"], data[\"y\"], ((data[\"last_x\"] - data[\"x\"])), ((data[\"last_y\"] - data[\"y\"])),\n",
    "                                 angles=\"xy\", scale_units=\"xy\", scale=1, width=0.0015, color=color) ## plot the arrows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "eJNx7Xrtn6gO",
    "outputId": "5e3229a5-1e45-473d-b682-7d4e70a72c8c"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame() ## Constructing DataFrame from a dictionary \n",
    "\n",
    "last_3x = []\n",
    "last_3y = []\n",
    "last_bboxes = []\n",
    "avg_distance = []\n",
    "\n",
    "## random auxiliary data\n",
    "## used to rough estimate the dx and dy values (velocities) in pixel/frame for the tracks\n",
    "\n",
    "for _, group in grouped: ## for all track ids\n",
    "    last_3x.append(group.tail(3).x.values) ## get the last 3 x points - outputs\n",
    "    last_3y.append(group.tail(3).y.values) ## get the last 3 y points - outputs\n",
    "    last_bboxes.append(list(group.tail(3).bbox.values)) ## get the last 3 bboxes - outputs\n",
    "    data = data.append(group.head(1)) ## get only the first group for any given track id -> should have only a single entry for track id)\n",
    "## output file from DeepSORT: track_ID, [x1,y1,x2,y2],class, frame_#\n",
    "\n",
    "## assign required data and convert between types.\n",
    "## the groupby is not inplace, so we add the required data from the created lists.\n",
    "data[\"last_3x\"] = last_3x\n",
    "data[\"last_3y\"] = last_3y\n",
    "data[\"last_x\"] = data[\"last_3x\"].str[2]\n",
    "data[\"last_y\"] = data[\"last_3y\"].str[2]\n",
    "data[\"last_bboxes\"] = last_bboxes\n",
    "\n",
    "data[\"distance\"] = ((data.x - data.last_x)**2 +\n",
    "                    ((data.y - data.last_y)**2))**0.5\n",
    "## cartesian distance\n",
    "## d = sqrt ((x1-x2)² + (y1-y2)²)\n",
    "\n",
    "## filtering data based on the minimun distance in pixels\n",
    "data = data[data[\"distance\"] > MIN_DISTANCE]\n",
    "\n",
    "## estimate of the dx and dy within 3 frames (delta position / delta frames = x - x` / 3)\n",
    "data[\"est_dx\"] = (data.last_3x.str[2] - data.last_3x.str[0])/3\n",
    "data[\"est_dy\"] = (data.last_3y.str[2] - data.last_3y.str[0])/3\n",
    "\n",
    "## generate the figure with the required size in pixels to fit the dpi\n",
    "## tis will be the reading from the first frame\n",
    "fig = plt.figure(figsize=(WIDTH/my_dpi, HEIGHT/my_dpi), dpi=my_dpi)\n",
    "img = plt.imread(\"first_frame.png\")\n",
    "plt.imshow(img, extent=[0, WIDTH, 0, HEIGHT])\n",
    "\n",
    "## plot arrows with different colors for each class\n",
    "plot_arrow(data.loc[data['class'] == 'car'], 'black')\n",
    "plot_arrow(data.loc[data['class'] == 'motorcycle'], 'green')\n",
    "plot_arrow(data.loc[data['class'] == 'bus'], 'orange')\n",
    "plot_arrow(data.loc[data['class'] == 'truck'], 'purple')\n",
    "\n",
    "## remove the axis before saving the images. Also, remove some other formatting that messes it up\n",
    "plt.axis('off')\n",
    "plt.gca().set_axis_off()\n",
    "plt.subplots_adjust(top=1, bottom=0, right=1, left=0,\n",
    "                    hspace=0, wspace=0)\n",
    "plt.margins(0, 0)\n",
    "\n",
    "plt.savefig(f\"detected_arrows_{filename}.png\", figsize=(\n",
    "    WIDTH/my_dpi, HEIGHT/my_dpi), dpi=my_dpi)\n",
    "\n",
    "plt.savefig(f\"composed_image_{filename}.png\",\n",
    "            bbox_inches='tight', pad_inches=0, dpi=my_dpi, figsize=(WIDTH/my_dpi, HEIGHT/my_dpi))\n",
    "\n",
    "#im = cv2.imread(f\"composed_image_{filename}.png\") ## read the image to select the RoIs\n",
    "#rois = cv2.selectROIs(\"RoI Selector\", im) ## select the ROIS in the frame \n",
    "## Selects ROIs on the given image. Function creates a window and allows user to select a ROIs using mouse. \n",
    "##Controls: use `space` or `enter` to finish current selection and start a new one, use `esc` to terminate \n",
    "##multiple ROI selection process. \n",
    "# roi = (x1,y1,w,h) (top left)\n",
    "\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "f3c3c0e1bee449e880d505a8456a4bb0"
     ]
    },
    "id": "tZkLjMrtiRR_",
    "outputId": "3562046a-0872-4cbf-8100-ec527ee94c4f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69d962d0bed47edaed25301bbb15c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Innotater(children=(HBox(children=(VBox(children=(ImagePad(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "targets_bboxes = np.zeros((1, 8, 4), dtype='int') # (x,y,w,h) for each region ## DOES NOT WORK ON COLAB!!\n",
    "SCALE = 2 \n",
    "\n",
    "Innotater( \n",
    "    ImageInnotation([f\"composed_image_{filename}.png\"], path='./', width= int(WIDTH/SCALE), height=int(HEIGHT/SCALE)), \n",
    "    [\n",
    "        RepeatInnotation(\n",
    "            (BoundingBoxInnotation, targets_bboxes),\n",
    "             max_repeats=8, min_repeats=1\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "id": "pm8MVvs8n-gN",
    "outputId": "982114ab-a97b-4ca0-b5b2-0754abbf6125"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luizg\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rectangle 1: [856, 43, 420, 465]\n",
      "Rectangle 2: [32, 249, 382, 565]\n"
     ]
    }
   ],
   "source": [
    "rois = []\n",
    "for bbox in targets_bboxes[0]: ## for bboxes\n",
    "    if (np.any(bbox)): ## if has size\n",
    "        rois.append(bbox) ## is a valid roi\n",
    "\n",
    "## generate the figure with the required size in pixels to fit the dpi\n",
    "## tis will be the reading from the first frame\n",
    "fig = plt.figure(figsize=(WIDTH/my_dpi, HEIGHT/my_dpi), dpi=my_dpi)\n",
    "img = plt.imread(f\"composed_image_{filename}.png\")\n",
    "plt.imshow(img, extent=[0, WIDTH, 0, HEIGHT])        \n",
    "        \n",
    "## convert the data given by the roi selector to a more usual format\n",
    "## roi selector gives it in the same way with 0,0 being the top left, whereas \n",
    "## matplotlib uses its 0,0 being on the bottom left.\n",
    "#rectangle_coords = [[roi[0], HEIGHT - roi[1] -\n",
    "#                     roi[3], roi[2], roi[3]] for roi in rois] ## get the roi box coordinates\n",
    "rectangle_coords = [[roi[0], HEIGHT - roi[1] - roi[3],\n",
    "                     roi[2], HEIGHT - roi[1]] for roi in rois] ## get the roi box coordinates\n",
    "\n",
    "## identify the rectangles\n",
    "for index, rect in enumerate(rectangle_coords, start=1):\n",
    "    print(f\"Rectangle {index}: {rect}\")\n",
    "\n",
    "## generate the rectangles to be plotted based on the data given by the RoI Selector.\n",
    "rectangles = [patches.Rectangle((coord[0], coord[1]), abs(coord[2]-coord[0]), abs(coord[3]-coord[1]),\n",
    "                                color=\"lime\", linewidth=2, fill=False) for coord in rectangle_coords]\n",
    "\n",
    "## generate a dictionary for the plot of the rectangles, which will be plotted with their numbers.\n",
    "rects = dict(enumerate(rectangles, start=1))\n",
    "\n",
    "ax = plt.gca() ## get the current axis to make te proper plot\n",
    "for r in rects:\n",
    "    ax.add_artist(rects[r])\n",
    "    rx, ry = rects[r].get_xy()\n",
    "    cx = rx + rects[r].get_width()/2.0\n",
    "    cy = ry + rects[r].get_height()/2.0\n",
    "\n",
    "    ax.annotate(r, (cx, cy), color='lime', weight='bold',\n",
    "                fontsize=72, ha='center', va='center')\n",
    "\n",
    "plt.axis('off')\n",
    "plt.gca().set_axis_off()\n",
    "plt.subplots_adjust(top=1, bottom=0, right=1, left=0,\n",
    "                    hspace=0, wspace=0)\n",
    "plt.margins(0, 0)\n",
    "\n",
    "## saves the figure with the rectangles drawn over it\n",
    "plt.savefig(f\"regions_{filename}.png\",\n",
    "            bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "## assistant func to verify if a point is inside the a bounding box (of the regions)\n",
    "def verifyIfInRect(x, y):\n",
    "    for number, bbox in enumerate(rectangle_coords, start=1):\n",
    "        # print(bbox[0] , (bbox[0] + bbox[2]), bbox[1] , (bbox[1] + bbox[3]))\n",
    "        if bbox[0] <= x <= (bbox[0] + bbox[2]) and bbox[1] <= y <= (bbox[1] + bbox[3]):\n",
    "            return number\n",
    "    return 0 ## if not inside any bbox\n",
    "\n",
    "## by using data.apply, we can apply our function to determine the rectangle the \n",
    "## x,y points are in // for entry and exit points.\n",
    "\n",
    "data[\"entry_box\"] = data.apply(lambda row: verifyIfInRect(\n",
    "    row[\"x\"], row[\"y\"]), axis=1)\n",
    "\n",
    "data[\"exit_box\"] = data.apply(lambda row: verifyIfInRect(\n",
    "    row[\"last_3x\"][-1], row[\"last_3y\"][-1]), axis=1)\n",
    "\n",
    "## save the dataframe to CSV (issues with lists, like the bbox)\n",
    "## but also save as an object - which is the case of the pickle file\n",
    "## to which we can have the same object opened on another folder without\n",
    "## having to re-convert the list\n",
    "data.to_csv(f\"classified_data_{filename}.csv\")\n",
    "pickle.dump(data,open(f\"classified_data_{filename}.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ROI_v.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "e012100dabced40fbf00f8470b0f8a21c87964cae25924970dac29b6fb52ebed"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "f3c3c0e1bee449e880d505a8456a4bb0": {
     "model_module": "jupyter-innotater",
     "model_name": "InnotaterModel",
     "state": {
      "_dom_classes": [
       "innotater-base"
      ],
      "_model_module": "jupyter-innotater",
      "_model_module_version": "~0.2.2",
      "_model_name": "InnotaterModel",
      "_view_count": null,
      "_view_module": "jupyter-innotater",
      "_view_module_version": "~0.2.2",
      "_view_name": "InnotaterView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d9ece8769be641f3b80fbb231da1206f",
       "IPY_MODEL_92ad51fcd80b4f82bf172abc3208fa2c"
      ],
      "index": 0,
      "is_dirty": false,
      "keyboard_shortcuts": true,
      "layout": "IPY_MODEL_bbf943d23f7c4aceb0f3860ba6c64652"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
